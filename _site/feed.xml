<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-03-06T22:07:15+05:30</updated><id>http://localhost:4000/feed.xml</id><title type="html">bgkiitg.github.io</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</subtitle><author><name>Benny George Kenkireth</name></author><entry><title type="html">Statistical Learning</title><link href="http://localhost:4000/blog/statisticallearning/" rel="alternate" type="text/html" title="Statistical Learning" /><published>2025-03-04T00:00:00+05:30</published><updated>2025-03-04T00:00:00+05:30</updated><id>http://localhost:4000/blog/statisticallearning</id><content type="html" xml:base="http://localhost:4000/blog/statisticallearning/"><![CDATA[<p>What really is a learning problem from a statistical point of view?</p>

<p><br />
Consider the function \(f(x)= x+ 2x^3\). The python code  given below samples this function
10000 times from the range \([-2,2]\). The sampled value at \(x\) is not exactly \(f(x)\) but has a “noise” which is a normally distributed random variable with mean 0 and variance 1.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">**</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># Generate 10000 x values in the range [-2, 2]
</span><span class="n">x_values</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>
<span class="n">y_values</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x_values</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>

<span class="c1"># Plot the points
</span><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_values</span><span class="p">,</span> <span class="n">y_values</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"Noisy Data"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"x values"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"y values"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Scatter Plot of Sampled Points"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Print the first 10 points as a sample
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Point on the curve: (x=</span><span class="si">{</span><span class="n">x_values</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, y=</span><span class="si">{</span><span class="n">y_values</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">)"</span><span class="p">)</span></code></pre></figure>

<p>The scatter plot of the data generated by this program is shown below.</p>

<p><img src="/assets/images/Figure_1.png" alt="Scatter Plot" class="center-image" /></p>

<p>The statistical learning problem is :</p>

<p>Given just this scatter plot(data) , can you guess what the underlying function was?</p>

<p>With this data, can you deduce that the  \(f(x)= x+ 2x^3\).  How much data do you need to make  this inference? If another person generated data using the same program, does her data also, when analysed give us the conclusion that the underlying function was  \(f(x)= x+ 2x^3\)?</p>

<p>In many real life situations, we just have the data. We do not know that the data was generated by a python code or some deterministic process plus some randomness. We abstract all these uncertainities to randomness and hope to recover the “true” function \(f\) from the data.</p>

<p>Formally, \(Y\) or the output variable or the dependent variable or the response is a random variable that has the following form</p>

\[Y = f(X) + \epsilon\]

<p>where \(f\) is an unknown but fixed function and \(\epsilon\) is a random variable with mean 0 and \(X\) is a vector of predictors or input variables. Note that the random variable \(Y\) is defined on the same probability space as the random variable \(\epsilon\). Further there is no randomness as such in \(X\). More precisely, \(Y(X)\) is a random variable for each \(X\)</p>

<p>We are given a bunch of \(Y\) samples and the corresponding \(X\) and are asked to guess what is \(f\). We may use this data and use statistical learning teachniques and come up with suitable choices for \(f\). Let’s denote this estimate function as \(\hat{f}\). We may use this to predict \(Y\) at a point \(X\) as \(\hat{f}(X)\). The closer \(\hat{f}\). is to \(f\), our estimation will be better. But even if we knew exactly what \(f\) there is be error as \(Y\) has a component from \(\epsilon\).</p>

<p>Even if we knew exactly the process, most often we do not know, that generated the data, \(Y\) is a random variable and thus will have a variance. Given \(\hat{f}\) and \(X\), our prediction will be  \(\hat{f}(X)\).  Then we have the following:</p>

\[E(Y - \hat{Y})^2 = E\left[ f(X) + \epsilon - \hat{f}(X) \right]^2



= \underbrace{[f(X) - \hat{f}(X)]^2}_{\text{Reducible}} + \underbrace{\operatorname{Var}(\epsilon)}_{\text{Irreducible}}\]

<p>The first error term is called reducible because it can be reduced by giving a better \(\hat{f}\). We can’t do that for the irreducible component.</p>

<p>Knowing the exat form of  \(f\) also helps us draw conclusions of the following kind:</p>

<ul>
  <li>Which input predictors are  important?</li>
  <li>Which input predict causes maximum change?</li>
  <li>For a given improvement in output, huch much should a certain predictor change?</li>
</ul>

<p>These questions are considered as “inference” related rather than  the predictor kind.</p>

<p>Now consider the problem of determining \(\hat{f}\). There are broadly two approaches:</p>

<ul>
  <li>Parametric</li>
</ul>

<p>Here we may assume that \(f\) have a certain shape, say linear, and then estimates the parameter using the data
 using methods like OLS etc.</p>

<ul>
  <li>Non-parametric methods</li>
</ul>

<p>Here we just try to get as close a fit as possible without being restricted by say the shape. An example would be A thin-plate spline method. These approaches allow for a much wide collection of shapes. We choose a smoothness and then try to find a function satisyfying the smoothness criteria.</p>

<p>Here is a list of statistical learning methods. The flexibility goes up  as we go down the list but the interpretability goes down as flexibility goes up.</p>

<ol>
  <li>Subset selection</li>
  <li>Lasso</li>
  <li>Least squares</li>
  <li>Generalized Additive models</li>
  <li>Trees</li>
  <li>Bagging, Boosting</li>
  <li>SVM</li>
  <li>Deep Learning</li>
</ol>

<p>The approaches may be classified as supervsed or Unsupervised on semisupervised on the basis of the type of data we have.
Further, on the basis of the values that \(Y\) can take, we may think of the problem as being classification or regression.</p>

<p>Once we have computed \(\hat{f}\), the quality of the fit can be quantified by computing the Mean Squared  Error on a test set. The  MSE on a test with \(n\) sample points  is given by</p>

\[MSE= \displaystyle \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{f}(x_i))^2\]]]></content><author><name>Benny George Kenkireth</name></author><category term="Blog" /><category term="ISLP" /><category term="Notes" /><category term="ML" /><summary type="html"><![CDATA[What really is a learning problem from a statistical point of view?]]></summary></entry><entry><title type="html">Bookmarks</title><link href="http://localhost:4000/blog/bookmarks/" rel="alternate" type="text/html" title="Bookmarks" /><published>2025-01-26T00:00:00+05:30</published><updated>2025-01-26T00:00:00+05:30</updated><id>http://localhost:4000/blog/bookmarks</id><content type="html" xml:base="http://localhost:4000/blog/bookmarks/"><![CDATA[<p>This page contains a list of internet bookmarks</p>

<p><a href="https://paulgraham.com/writing44.html">On writing by Paul Graham</a></p>

<p><a href="https://www.youtube.com/watch?v=ji5_MqicxSo">Last Lecture by Randy Pausch</a></p>

<p><a href="https://www.youtube.com/watch?v=V4riykgUS94">Getting started with Anaconda and Python on a Mac</a></p>

<p><a href="https://www.youtube.com/watch?v=bvi37IbJXS4">Push to Github from Terminal</a></p>]]></content><author><name>Benny George Kenkireth</name></author><category term="Blog" /><category term="bookmarks" /><summary type="html"><![CDATA[This page contains a list of internet bookmarks]]></summary></entry><entry><title type="html">Risk Neutral Pricing and Martingales</title><link href="http://localhost:4000/blog/riskneutralprices/" rel="alternate" type="text/html" title="Risk Neutral Pricing and Martingales" /><published>2025-01-26T00:00:00+05:30</published><updated>2025-01-26T00:00:00+05:30</updated><id>http://localhost:4000/blog/riskneutralprices</id><content type="html" xml:base="http://localhost:4000/blog/riskneutralprices/"><![CDATA[<p>The relationship betweek risk neutral pricing and discounted wealth processes in the binomial asset pricing model.</p>

<p><strong>Theorem</strong> 
<br />
Consider the binomial asset pricing model with</p>

\[0 &lt; d &lt; 1+r &lt;  u\]

<p>Let the risk neutral probabilities be</p>

\[\tilde{p} = \frac{1+r-d}{u-d} \textrm{ and } \tilde{q} = \frac{u-(1+r)}{u-d}\]

<p>Then, under the risk neutral measure, the discounted stock price process (as well as any wealth process) will be a martingale.</p>

<p><strong>Proof</strong></p>

<p>The discounted stock process is given by</p>

\[X_n = \frac{S_{n}}{(1+r)^{n}}\]

<p>\(X_n\) denotes the price of the stock at time \(n\) discounted by the interest rate factor for \(n\) time steps. This is an adapted process. The value of the random variable \(X_n\) is fully determined by the first \(n\) coin tosses. For this to be a martingale  we must have</p>

\[\tilde{\mathbb{E}}_n[X_{n+1}] = X_n\]

<p>Note that \(X_{n+1}\) is equal to \(X_n\frac{S_{n+1}}{(1+r)}\). Thus the expectation on the left becomes  \(X_n*\tilde{\mathbb{E}}_n[\frac{T_{n+1}}{1+r}]\).  \(\ T_{n+1}\) can take two values $u$ and $d$ depending only on the \(n+1^{st}\) coin toss. So the expectation of \(T_{n+1}\) under  under neutral probability turns out to be \(1+r\). Plugging in this value, we can verify the theorem.</p>

<p>Note that both the stock and thebond grows at rate $1+r$ per period under the risk neutral measure. Thus any combination of hese two assets would also grow at rate $1+r$.  More specifically,
let us consider an adapted portfolio process, i.e. the investor decide to keep \(\Delta_n\) shares at at time \(n\) where $\Delta_n$ is dictated by the tosses upto \(n\).  If \(X_0\) is the initial weath, then the recursive wealth equation can be written as</p>

\[X_{n+1} = \Delta_n S_n + (1+r)(X_n- \Delta_n S_n)\]

<p>One can show that this wealth process is also a martingale under risk neutral measure.</p>]]></content><author><name>Benny George Kenkireth</name></author><category term="Blog" /><category term="Finance" /><category term="Notes" /><category term="Shreve" /><summary type="html"><![CDATA[The relationship betweek risk neutral pricing and discounted wealth processes in the binomial asset pricing model.]]></summary></entry><entry><title type="html">Euler’s Theorem</title><link href="http://localhost:4000/blog/Euler/" rel="alternate" type="text/html" title="Euler’s Theorem" /><published>2025-01-16T00:00:00+05:30</published><updated>2025-01-16T00:00:00+05:30</updated><id>http://localhost:4000/blog/Euler</id><content type="html" xml:base="http://localhost:4000/blog/Euler/"><![CDATA[<p>Euler’s theorem is a simple theorem from graph theory. If states that if \(G\) is a planar graph with \(v\) vertices and \(e\) edges and \(f\) faces, then</p>

\[v-e+f =2\]

<p>There is a simple inductive proof. We will see a “topological” proof  of this result.</p>

<h2 id="key-proof-steps">Key proof steps</h2>
<ul>
  <li>Define polyhedrons.</li>
  <li>Choose any tree \(T\) on the “polyhedron”</li>
  <li>Consider the “dual” tree \(\Gamma\) of the tree \(T\).</li>
  <li>As \(\Gamma\) and \(T\) are both trees, we have \(v_{G}-e_{G}\) =1.</li>
  <li>Adding these equations, we have Euler’s Theorem.</li>
</ul>

<h4 id="polyhedron">Polyhedron</h4>

<p>Intuitively, polyhedrons must look like objects shown below.</p>
<hr />

<div style="text-align: center;">
<script type="text/tikz">

\begin{tikzpicture}
  \begin{scope}
    

\coordinate (A1) at (0,0);
\coordinate (A2) at (3,0);
\coordinate (A3) at (5,1.5);
\coordinate (A4) at (2,1.5);

\coordinate (B1) at (-1,2);
\coordinate (B2) at (2.5,2);
\coordinate (B3) at (4,2.75);
\coordinate (B4) at (5,3.5);
\coordinate (B5) at (1,3.5);

\coordinate (C) at (3,1);


\draw (A1) -- (A2) -- (A3);
\draw[dashed] (A3) -- (A4)--(A1);
\draw (B2)--  (B1) -- (B5) -- (B4) -- (B3);
\draw (A2) -- (C) -- (B2) --(B3) --(C);
\draw (A1) -- (B1);
\draw (A3) -- (B4);
\draw[dashed] (A4) -- (B5);
  \end{scope}
  \begin{scope}[xshift=7cm,scale=0.5]

  \coordinate (C1) at (4,0);
  \coordinate (C2) at (7,0);
  \coordinate (C3) at (9,2);
  \coordinate (C4) at (5.5,4);
  \coordinate (C5) at (2,2);
  \draw (C5)--(C1)--(C2)--(C3);
  \draw[dashed] (C3) --(C4)--(C5);

  
  \coordinate (D1) at (4,6);
  \coordinate (D2) at (7,6);
  \coordinate (D3) at (9,8);
  \coordinate (D4) at (5.5,10);
  \coordinate (D5) at (2,8);
  \draw (D1)--(D2)--(D3)--(D4)--(D5)--cycle;


  \draw (C1) --(D1);
  \draw (C2) --(D2);
  \draw (C3) --(D3);
  \draw (C5) --(D5);
  \draw[dashed] (C4)--(D4);

  \coordinate (E1) at (5,7);
  \coordinate (E2) at (6,7);
  \coordinate (E3) at (6.75,8);
  \coordinate (E4) at (5.5,8.5);
  \coordinate (E5) at (4.25,8);

  \draw (E1)--(E2)--(E3)--(E4)--(E5)--cycle;

  \coordinate (F1) at (5,6.5);
  \coordinate (F2) at (6,6.5);
  \coordinate (F3) at (6.75,7.5);
  \coordinate (F4) at (5.5,8);
  \coordinate (F5) at (4.25,7.5);

  \draw[dashed] (F1)--(F2)--(F3)--(F4)--(F5)--cycle;
  \draw[dashed] (E1)--(F1);
  \draw[dashed] (E2)--(F2);
  \draw[dashed] (E3)--(F3);
  \draw[dashed] (E4)--(F4);
  \draw[dashed] (E5)--(F5);

  \fill[blue!40!white, opacity=0.6] (E1) -- (F1) -- (F2) -- (E2) -- cycle;
  \fill[blue!40!white,opacity=0.6] (E2) -- (F2) -- (F3) -- (E3) -- cycle;
  \fill[blue!40!white,opacity=0.6] (E3) -- (F3) -- (F4) -- (E4) -- cycle;
  \fill[blue!40!white,opacity=0.6] (E4) -- (F4) -- (F5) -- (E5) -- cycle;
  \fill[blue!40!white,opacity=0.6] (E5) -- (F5) -- (F1) -- (E1) -- cycle;

\end{scope}
\end{tikzpicture}

</script>
</div>
<hr />

<p>What is not a polyhedra looks like the objects shown below.  One of them has a  “cavity”  and the other has a  “hole”   through it.</p>

<hr />

<div style="text-align: center;">

<script type="text/tikz">
\begin{tikzpicture}
\begin{scope}
% Define the vertices of the outer cube
\coordinate (A) at (0,0,0); % Front-bottom-left
\coordinate (B) at (3,0,0); % Front-bottom-right
\coordinate (C) at (3,3,0); % Front-top-right
\coordinate (D) at (0,3,0); % Front-top-left
\coordinate (E) at (0,0,-3); % Back-bottom-left
\coordinate (F) at (3,0,-3); % Back-bottom-right
\coordinate (G) at (3,3,-3); % Back-top-right
\coordinate (H) at (0,3,-3); % Back-top-left

% Define the vertices of the inner cavity (smaller cube)
\coordinate (A1) at (1,1,-1); % Front-bottom-left
\coordinate (B1) at (2,1,-1); % Front-bottom-right
\coordinate (C1) at (2,2,-1); % Front-top-right
\coordinate (D1) at (1,2,-1); % Front-top-left
\coordinate (E1) at (1,1,-2); % Back-bottom-left
\coordinate (F1) at (2,1,-2); % Back-bottom-right
\coordinate (G1) at (2,2,-2); % Back-top-right
\coordinate (H1) at (1,2,-2); % Back-top-left

% Draw the outer cube
\fill[blue!20!white] (A) -- (B) -- (C) -- (D) -- cycle; % Front face
\fill[blue!25!white] (E) -- (F) -- (G) -- (H) -- cycle; % Back face
\fill[blue!30!white] (A) -- (B) -- (F) -- (E) -- cycle; % Bottom face
\fill[blue!35!white] (D) -- (C) -- (G) -- (H) -- cycle; % Top face
\fill[blue!40!white] (B) -- (C) -- (G) -- (F) -- cycle; % Right face
\fill[blue!45!white] (A) -- (D) -- (H) -- (E) -- cycle; % Left face

% Draw the inner cavity (hole)
\fill[white] (A1) -- (B1) -- (C1) -- (D1) -- cycle; % Front face
\fill[white] (E1) -- (F1) -- (G1) -- (H1) -- cycle; % Back face
\fill[white] (A1) -- (B1) -- (F1) -- (E1) -- cycle; % Bottom face
\fill[white] (D1) -- (C1) -- (G1) -- (H1) -- cycle; % Top face
\fill[white] (B1) -- (C1) -- (G1) -- (F1) -- cycle; % Right face
\fill[white] (A1) -- (D1) -- (H1) -- (E1) -- cycle; % Left face

% Draw edges of the outer cube
\draw[thick] (A) -- (B) -- (C) -- (D) -- cycle; % Front face
\draw[thick] (E) -- (F) -- (G) -- (H) -- cycle; % Back face
\draw[thick] (A) -- (E);
\draw[thick] (B) -- (F);
\draw[thick] (C) -- (G);
\draw[thick] (D) -- (H);

% Draw edges of the inner cavity
\draw[thick, dashed] (A1) -- (B1) -- (C1) -- (D1) -- cycle; % Front face
\draw[thick, dashed] (E1) -- (F1) -- (G1) -- (H1) -- cycle; % Back face
\draw[thick, dashed] (A1) -- (E1);
\draw[thick, dashed] (B1) -- (F1);
\draw[thick, dashed] (C1) -- (G1);
\draw[thick, dashed] (D1) -- (H1);
\end{scope}

\begin{scope}[xshift = 10cm,scale=0.6]
  \coordinate (A1) at (0,0);
  \coordinate (A2) at (3,0);
  \coordinate (A3) at (4,2);
  \coordinate (A4) at (1,2);
  \draw (A1)--(A2)--(A3)--(A4)--cycle;
  \coordinate (B1) at (0,5);
  \coordinate (B2) at (3,5);
  \coordinate (B3) at (4,7);
  \coordinate (B4) at (1,7);
  \draw (B1)--(B2)--(B3)--(B4)--cycle;
  \draw (A1) -- (B1);
  \draw (A2) -- (B2);
  \draw (A3) -- (B3);
  \draw[dashed] (A4) -- (B4);

  \coordinate (C1) at (1.50,0.75);
  \coordinate (C2) at (2.25,0.75);
  \coordinate (C3) at (2.50,1.25);
  \coordinate (C4) at (1.75,1.25);
  \draw (C1)--(C2)--(C3)--(C4)--cycle;

  \coordinate (D1) at (1.50,5.75);
  \coordinate (D2) at (2.25,5.75);
  \coordinate (D3) at (2.50,6.25);
  \coordinate (D4) at (1.75,6.25);
  \draw (D1)--(D2)--(D3)--(D4)--cycle;
  \draw[dashed] (C1) -- (D1);
  \draw[dashed] (C2) -- (D2);
  \draw[dashed] (C3) -- (D3);
  \draw[dashed] (C4) -- (D4);
  \fill[blue!40!white,opacity=0.6] (C1) -- (D1) -- (D2) -- (C2) -- cycle;
  \fill[blue!40!white,opacity=0.6] (C2) -- (D2) -- (D3) -- (C3) -- cycle;
  \fill[blue!40!white,opacity=0.6] (C3) -- (D3) -- (D4) -- (C4) -- cycle;
  \fill[blue!40!white,opacity=0.6] (C4) -- (D4) -- (D1) -- (C1) -- cycle;
  
\end{scope}

\end{tikzpicture}
</script>
</div>
<hr />

<dl>
  <dt>We will define  what constitutes a polyhedron in the context of Euler’s Theorem.</dt>
  <dt>Polyhedron</dt>
  <dd>A polyhedron is a finite collection of plane polygons such that
    <ul>
      <li>if two polygons intersect, there do so along an edge or a vertex and each edge is shared by exactly two poolygons.</li>
      <li>The polygons which share a vertex can be arranged cyclically such that the adjacent polygons along the cycle has a common edge.</li>
    </ul>
  </dd>
</dl>

<h1 id="eulers-theorem"><strong>Euler’s Theorem</strong></h1>

<p>Let  <em>P</em> be a connected  polyhedron  such that any loop on <em>P</em> separates <em>P</em>
into two pieces. Then, \(v-e+f =2\).</p>

<p><strong>Proof:</strong></p>

<p>Take any tree  \(T_{1}\) on the polyhedron. We will define a dual of this tree, namely \(T_{2}\). The vertices in the dual are faces(plane polygons) of the polyhedron. Two vertices have an edge between them if the corresponding faces share an edge that does not belong to \(T_{1}\). Note that \(v(T_{1}) - e(T_{1}) = 1\) and that \(v(T_{2}) - e(T_{2})= 1\). Note that \(v(T_{1}) = v\) and
 \(v(T_{2}) = f\) and \(e(T_{1}) + e(T_{2}) = e\).</p>

<h3 id="references">References</h3>

<ol>
  <li>Armstrong, M.A., <em>Basic Topology</em>, Springer UTM  2013</li>
</ol>]]></content><author><name>Benny George Kenkireth</name></author><category term="Blog" /><category term="Topology" /><category term="Examples" /><category term="Graph" /><category term="Tikz" /><summary type="html"><![CDATA[Euler’s theorem is a simple theorem from graph theory. If states that if \(G\) is a planar graph with \(v\) vertices and \(e\) edges and \(f\) faces, then]]></summary></entry><entry><title type="html">A post with TikZJax</title><link href="http://localhost:4000/blog/tikzjax/" rel="alternate" type="text/html" title="A post with TikZJax" /><published>2025-01-12T00:00:00+05:30</published><updated>2025-01-12T00:00:00+05:30</updated><id>http://localhost:4000/blog/tikzjax</id><content type="html" xml:base="http://localhost:4000/blog/tikzjax/"><![CDATA[<p>This is an example post with TikZ code. TikZJax converts script tags (containing TikZ code) into SVGs.</p>

<script type="text/tikz">
\begin{tikzpicture}
    \draw[step=.5cm,style=help lines] (0,0) grid (12,4);
    \draw[red,fill=black!60!red] (6,2) circle [radius=1.5];
    \draw[green,fill=black!60!green] (6,2) circle [x radius=1.5cm, y radius=10mm];
    \draw[blue,fill=black!60!blue] (6,2) circle [x radius=1cm, y radius=5mm, rotate=30];
\end{tikzpicture}
</script>]]></content><author><name>Benny George Kenkireth</name></author><category term="Blog" /><category term="LaTeX" /><category term="Examples" /><summary type="html"><![CDATA[This is an example post with TikZ code. TikZJax converts script tags (containing TikZ code) into SVGs.]]></summary></entry><entry><title type="html">LaTeX Samples</title><link href="http://localhost:4000/blog/LaTeX-samples/" rel="alternate" type="text/html" title="LaTeX Samples" /><published>2025-01-11T00:00:00+05:30</published><updated>2025-01-11T00:00:00+05:30</updated><id>http://localhost:4000/blog/LaTeX-samples</id><content type="html" xml:base="http://localhost:4000/blog/LaTeX-samples/"><![CDATA[<p>\[p(\theta) = \mathbf{\prod}_{i,c}p(\mathbf{\theta}^i(c))\]</p>

\[\begin{aligned} 
a^2 + b^2 &amp;= c^2 \\ 
E &amp;= M \cdot C^2 \\ 
&amp;= xy + \mathbb{E} 
\end{aligned}\]

\[{X}_{0}  \\
  X_0 (working) \\
  \hat{a}_{b}   \\
  \hat{a}_b  \\
  \hat{a}_{b+c} \\\]

\[f(n) =
      \begin{cases}
      n/2,  &amp; \text{if $n$ is even} \\
      3n+1, &amp; \text{if $n$ is odd}
      \end{cases}\]

\[\frac{4}{3}\]

<p>\(p(\theta) = \mathbf{\prod}_{i,c}p(\mathbf{\theta}^i(c))\) inline formula  yay
$ f(x) = x^2$</p>

<p>https://choimon.github.io/blog/mathjax-for-minimalmistakes-githubpage/</p>]]></content><author><name>Benny George Kenkireth</name></author><category term="Blog" /><category term="LaTeX" /><category term="Examples" /><summary type="html"><![CDATA[\[p(\theta) = \mathbf{\prod}_{i,c}p(\mathbf{\theta}^i(c))\]]]></summary></entry><entry><title type="html">Welcome</title><link href="http://localhost:4000/blog/Welcome/" rel="alternate" type="text/html" title="Welcome" /><published>2025-01-10T00:00:00+05:30</published><updated>2025-01-10T00:00:00+05:30</updated><id>http://localhost:4000/blog/Welcome</id><content type="html" xml:base="http://localhost:4000/blog/Welcome/"><![CDATA[<p>Welcome to my blog.  I have reinvented “wheels” many a time. 
The main purpose of this blog is to document things that I 
find useful in my professional life. Of course, it will be great if somebody
else finds it helpful.</p>]]></content><author><name>Benny George Kenkireth</name></author><category term="Blog" /><category term="Social" /><summary type="html"><![CDATA[Welcome to my blog. I have reinvented “wheels” many a time. The main purpose of this blog is to document things that I find useful in my professional life. Of course, it will be great if somebody else finds it helpful.]]></summary></entry></feed>